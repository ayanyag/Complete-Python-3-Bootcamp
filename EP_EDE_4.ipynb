{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNv2hpwmRiSWlx7IQl5byuE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayanyag/Complete-Python-3-Bootcamp/blob/master/EP_EDE_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook Overview and Requirements"
      ],
      "metadata": {
        "id": "9yXhFSZSRxBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notebook Overview and Requirements**\n",
        "\n",
        "This Google Colab notebook automates the process of generating and validating a regulatory XBRL report. Specifically, this script is configured to update and validate the Financial information on the safeguarding system reports:\n",
        "\n",
        "- EP_4-1: Salvaguarda de fondos de usuarios de servicios de pago y dinero electrónico [7510]\n",
        "\n",
        "- EP_4-2: Cuentas de salvaguarda (a) [7511]\n",
        "\n",
        "- EP_4-3: Detalle de cuentas de salvaguarda (a) [7512]\n",
        "\n",
        "The workflow reads new data from an Excel file, updates a template XBRL instance, validates the result against the official taxonomies, and packages the final report into a zip archive for submission.\n",
        "\n",
        "\n",
        "**Before You Begin**\n",
        "\n",
        "Please ensure you have the following files prepared and in the correct locations:\n",
        "\n",
        "1. In your Google Drive (in the folder specified in the script, e.g., /MyDrive/BDE_REPORTING_SCRIPT/XBRL_Taxonomies/):\n",
        "\n",
        "    - All necessary taxonomy packages as .zip files (e.g., es-bde.zip, Full_taxonomy_release_4.1.zip, etc.). These are stored in Drive to avoid re-uploading large files every session.\n",
        "\n",
        "2. Ready to upload to this Colab session:\n",
        "\n",
        "    - The source Excel file containing the data for the current reporting period (e.g., EP_4_MAY25.xlsx).\n",
        "    - The base XBRL instance file from the previous period, which will be used as a template (e.g., ES6885_..._20250430.xbrl).\n",
        "\n",
        "**How to Use**\n",
        "\n",
        "Execute the cells in this notebook from top to bottom. The initial cells perform a one-time setup for the session (installing tools and connecting to your Drive), and the final cells carry out the report generation and validation. Review the output of the final cell to confirm the validation was successful.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GxSRIbDjqLj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install external software and Python libraries"
      ],
      "metadata": {
        "id": "VCyr-NmnSbGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Install Necessary Libraries (Run Once Per Session) ---\n",
        "\n",
        "\"\"\"\n",
        "    This cell prepares the Google Colab environment by installing all necessary\n",
        "    external software and Python libraries required for the entire workflow.\n",
        "\n",
        "    It performs the following actions:\n",
        "      1. Installs 'p7zip-full': A command-line utility needed to decompress\n",
        "          .7z archive files, which some of the taxonomy packages use.\n",
        "      2. Installs Python Libraries: Uses 'pip' to install pandas, openpyxl,\n",
        "          and python-dateutil for data manipulation and reading Excel files.\n",
        "      3. Installs Arelle: Fetches and installs the Arelle XBRL processor\n",
        "          directly from its official GitHub repository to ensure access to the\n",
        "          command-line tool.\n",
        "\n",
        "    USAGE:\n",
        "    This cell should be run ONLY ONCE at the beginning of each new Colab session,\n",
        "    as the environment is reset every time it is disconnected.\n",
        "    \"\"\"\n",
        "\n",
        "print(\"Installing libraries...\")\n",
        "!sudo apt-get -y install p7zip-full\n",
        "!pip install openpyxl python-dateutil pandas -q\n",
        "!pip install openpyxl python-dateutil pandas lxml -q\n",
        "!pip install git+https://github.com/Arelle/Arelle.git -q\n",
        "print(\"\\n✅ Libraries installed successfully.\")\n",
        "print(\"\\nYou can now run the main script in the next cell.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Qn2CDARS3aK",
        "outputId": "b63e2614-799b-43b5-c7d0-58de575a62e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing libraries...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for arelle-release (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "✅ Libraries installed successfully.\n",
            "\n",
            "You can now run the main script in the next cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "E5nKcoTrSgbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Mount Google Drive (Run Once Per Session) ---\n",
        "\n",
        "\"\"\"\n",
        "    This cell mounts the user's personal Google Drive to the Colab environment,\n",
        "    making its contents accessible to the script.\n",
        "\n",
        "    WHY IT'S NECESSARY:\n",
        "    This connection is essential for the script to access the large XBRL\n",
        "    taxonomy packages (.zip files). Storing these files in Google Drive is\n",
        "    efficient because it avoids the need to upload them every session.\n",
        "\n",
        "    IMPORTANT USER INTERACTION:\n",
        "    When you run this cell, you will be prompted with a URL. You must:\n",
        "      1. Click the link.\n",
        "      2. Sign in to your Google account.\n",
        "      3. Grant permission for Colab to access your Drive.\n",
        "      4. Copy the authorization code that Google provides.\n",
        "      5. Paste that code back into the input box in this cell and press Enter.\n",
        "\n",
        "    USAGE:\n",
        "    This cell should be run once per session, after the libraries in Cell 1\n",
        "    have been installed.\n",
        "    \"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "print(\"Connecting to Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\n✅ Google Drive mounted successfully at /content/drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-pY-abDlOhc",
        "outputId": "37eb3381-08af-4aed-ef80-731f30ee51d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to Google Drive...\n",
            "Mounted at /content/drive\n",
            "\n",
            "✅ Google Drive mounted successfully at /content/drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "2HoxAp5oUDnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Import Libraries (Run Once Per Session) ---\n",
        "\n",
        "\"\"\"\n",
        "    This cell imports all the necessary Python libraries and modules into the\n",
        "    current Colab session's memory.\n",
        "\n",
        "    By placing all imports in a separate cell, we ensure that these tools are\n",
        "    loaded only once, which makes re-running the main script faster and keeps\n",
        "    the overall notebook more organized.\n",
        "\n",
        "    Key Libraries Imported:\n",
        "      - xml.etree.ElementTree: For creating, parsing, and writing XML/XBRL files.\n",
        "      - openpyxl & pandas: For reading and handling data from the .xlsx files.\n",
        "      - re: For using regular expressions to find codes within cell text.\n",
        "      - datetime, dateutil, calendar: For all date-related logic, like calculating\n",
        "        the next reporting month.\n",
        "      - zipfile, os, subprocess: For file system operations like creating folders,\n",
        "        unzipping archives, and running external command-line tools.\n",
        "      - arelle: Specific classes imported from the Arelle XBRL processor for\n",
        "        validation tasks.\n",
        "\n",
        "    USAGE:\n",
        "    This cell should be run once per session, after Cell 1 (Installation) and\n",
        "    Cell 2 (Drive Mount) have completed successfully.\n",
        "    \"\"\"\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "from lxml import etree as ET\n",
        "import openpyxl\n",
        "import pandas as pd\n",
        "import re\n",
        "from datetime import date, datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import calendar\n",
        "import zipfile\n",
        "import os\n",
        "import subprocess\n",
        "from arelle import Cntlr\n",
        "from arelle.FileSource import FileSource\n",
        "\n",
        "print(\"✅ Libraries imported successfully. Ready for the next steps.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVZuxO4NoIKS",
        "outputId": "68573b8a-0d5a-4dec-ab22-516ab962eecc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Libraries imported successfully. Ready for the next steps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-flight check"
      ],
      "metadata": {
        "id": "57MXPD39UK4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- File Explorer & Pre-flight Check (Run Before Main Script) ---\n",
        "\n",
        "\"\"\"\n",
        "    This cell acts as a 'File Explorer' for your Google Drive. It lists all\n",
        "    files within your specified taxonomy directory and shows their size and last\n",
        "    modified date.\n",
        "\n",
        "    WHY IT'S NECESSARY:\n",
        "    This is an essential pre-flight check. By running this cell, you can:\n",
        "      1. Visually confirm that all required taxonomy packages are present.\n",
        "      2. Quickly check the 'Last Modified' date of your files and compare them\n",
        "        with the latest versions available on the official regulator websites\n",
        "        to decide if you need to download updates.\n",
        "\n",
        "    HOW TO USE:\n",
        "    Run this cell after mounting your Google Drive to audit your files.\n",
        "    \"\"\"\n",
        "\n",
        "print(\"--- Listing contents of your Google Drive taxonomy folder... ---\")\n",
        "\n",
        "# This path should exactly match the 'drive_path' variable in the next cell.\n",
        "drive_path = \"/content/drive/MyDrive/BDE_REPORTING_SCRIPT/XBRL_Taxonomies/\"\n",
        "\n",
        "if not os.path.isdir(drive_path):\n",
        "    print(f\"❌ ERROR: The directory was not found: {drive_path}\")\n",
        "    print(\"Please ensure your Google Drive is mounted and the path is correct.\")\n",
        "else:\n",
        "    try:\n",
        "        # Get a list of all files in the directory\n",
        "        files_in_drive = os.listdir(drive_path)\n",
        "\n",
        "        if not files_in_drive:\n",
        "            print(\"The folder exists but is empty.\")\n",
        "        else:\n",
        "            print(f\"\\nFound {len(files_in_drive)} files in '{drive_path}':\")\n",
        "            # Loop through each file and print its details\n",
        "            for filename in sorted(files_in_drive):\n",
        "                full_path = os.path.join(drive_path, filename)\n",
        "                # Get file size and convert to MB\n",
        "                size_in_mb = os.path.getsize(full_path) / (1024 * 1024)\n",
        "                # Get last modified timestamp and format it\n",
        "                mod_time = os.path.getmtime(full_path)\n",
        "                mod_date_str = datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "                print(f\"  - File: {filename:<35} | Size: {size_in_mb:>5.2f} MB | Last Modified: {mod_date_str}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred while listing files: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xclT3B_s0qIR",
        "outputId": "511ff626-4b28-429b-b67b-2d3d70a1ac53"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Listing contents of your Google Drive taxonomy folder... ---\n",
            "\n",
            "Found 5 files in '/content/drive/MyDrive/BDE_REPORTING_SCRIPT/XBRL_Taxonomies/':\n",
            "  - File: Full_taxonomy_release_4.1.zip       | Size: 102.52 MB | Last Modified: 2025-06-19 09:51:48\n",
            "  - File: es-bde-aux.zip                      | Size:  0.07 MB | Last Modified: 2025-06-19 09:42:35\n",
            "  - File: es-bde.zip                          | Size: 63.57 MB | Last Modified: 2025-06-19 10:58:56\n",
            "  - File: eu-eurofiling.zip                   | Size:  0.16 MB | Last Modified: 2025-06-19 09:39:57\n",
            "  - File: srf-eac_full_taxonomy_0.zip         | Size: 12.14 MB | Last Modified: 2025-06-19 09:44:15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local taxonomy enviroment"
      ],
      "metadata": {
        "id": "aEYRVMjWUQvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prepare Local Taxonomy Environment ---\n",
        "\n",
        "\"\"\"\n",
        "    This cell is responsible for preparing the complete local taxonomy environment.\n",
        "    It takes all the required taxonomy packages (which can be a mix of standard\n",
        "    .zip and .7z formats) from Google Drive and extracts them into a single,\n",
        "    structured folder within the Colab session.\n",
        "\n",
        "    KEY LOGIC:\n",
        "    1. Efficiency Check: It first checks if the environment has already been\n",
        "      prepared by looking for the existence of all key sub-folders (e.g.,\n",
        "      'www.bde.es', 'www.eba.europa.eu', etc.). If they all exist, it skips\n",
        "      the time-consuming extraction process.\n",
        "    2. Smart Decompression: If the environment is not ready, it iterates\n",
        "      through each archive. It intelligently detects its format (standard Zip\n",
        "      or 7-Zip) and uses the correct tool to decompress it.\n",
        "\n",
        "    WHY IT'S NECESSARY:\n",
        "    This step creates a comprehensive local mirror of all required taxonomies.\n",
        "    This allows the final validation script (in the next cell) to run in a\n",
        "    true offline mode using URL remapping, which is essential to bypass the\n",
        "    \"403 Forbidden\" network errors.\n",
        "\n",
        "    USAGE:\n",
        "    Run this cell once per session after installing libraries (Cell 1) and\n",
        "    mounting Google Drive (Cell 2). The successful completion of this cell is a\n",
        "    prerequisite for running the main script.\n",
        "    \"\"\"\n",
        "\n",
        "print(\"--- Preparing Local Taxonomy Environment ---\")\n",
        "\n",
        "# --- Define File Paths ---\n",
        "drive_path = \"/content/drive/MyDrive/BDE_REPORTING_SCRIPT/XBRL_Taxonomies/\"\n",
        "taxonomy_zip_files = [\n",
        "    drive_path + 'es-bde.zip',\n",
        "    drive_path + 'es-bde-aux.zip',\n",
        "    drive_path + 'eu-eurofiling.zip',\n",
        "    drive_path + 'srf-eac_full_taxonomy_0.zip',\n",
        "    drive_path + 'Full_taxonomy_release_4.1.zip'\n",
        "]\n",
        "local_taxonomy_folder = 'local_taxonomies'\n",
        "\n",
        "# --- Define all subfolders that should exist after a full extraction ---\n",
        "# These correspond to the URL remapping rules in the main script.\n",
        "expected_subfolders = [\n",
        "    os.path.join(local_taxonomy_folder, 'www.bde.es'),\n",
        "    os.path.join(local_taxonomy_folder, 'www.eba.europa.eu'),\n",
        "    os.path.join(local_taxonomy_folder, 'www.eurofiling.info'),\n",
        "    os.path.join(local_taxonomy_folder, 'EBA_XBRL_4.0_Severity_4.0.0.1'),\n",
        "    os.path.join(local_taxonomy_folder, 'www.srb.europa.eu')\n",
        "]\n",
        "\n",
        "# --- NEW: Check if ALL expected subfolders already exist ---\n",
        "is_prepared = all(os.path.isdir(path) for path in expected_subfolders)\n",
        "\n",
        "if is_prepared:\n",
        "    print(f\"✅ Local taxonomy environment already exists at '{local_taxonomy_folder}'. Skipping extraction.\")\n",
        "\n",
        "else:\n",
        "    # If the check path doesn't exist, run the full extraction process.\n",
        "    print(f\"Local taxonomy environment not found. Starting full extraction process...\")\n",
        "    try:\n",
        "\n",
        "        # --- Create local folder and unzip all packages ---\n",
        "        print(f\"\\n--- Unzipping all taxonomy packages ---\")\n",
        "        os.makedirs(local_taxonomy_folder, exist_ok=True)\n",
        "\n",
        "        files_unzipped = 0\n",
        "        for zip_file_path in taxonomy_zip_files:\n",
        "            if not os.path.exists(zip_file_path):\n",
        "                print(f\"WARNING: Could not find file at '{zip_file_path}'\")\n",
        "                continue\n",
        "\n",
        "            print(f\"Processing: {os.path.basename(zip_file_path)}...\")\n",
        "            result = subprocess.run(['file', zip_file_path], capture_output=True, text=True)\n",
        "            file_type_info = result.stdout\n",
        "\n",
        "            if '7-zip archive' in file_type_info:\n",
        "                print(f\"  -> Detected as 7-Zip archive. Extracting with 7z...\")\n",
        "                os.system(f'7z x \"{zip_file_path}\" -o\"{local_taxonomy_folder}\" -y > /dev/null')\n",
        "                files_unzipped += 1\n",
        "            elif 'Zip archive' in file_type_info:\n",
        "                print(f\"  -> Detected as standard Zip archive. Extracting...\")\n",
        "                with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(local_taxonomy_folder)\n",
        "                files_unzipped += 1\n",
        "            else:\n",
        "                print(f\"  -> WARNING: Could not determine archive type for {os.path.basename(zip_file_path)}. Skipping.\")\n",
        "\n",
        "        if files_unzipped < len(taxonomy_zip_files):\n",
        "            print(f\"\\nWARNING: Only {files_unzipped} out of {len(taxonomy_zip_files)} packages were unzipped.\")\n",
        "        else:\n",
        "            print(f\"\\n✅ Local taxonomy environment is now ready. All {files_unzipped} packages unzipped.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred during unzipping: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CizZ_q-my_68",
        "outputId": "9d2a1b51-ea3c-4f3c-a747-2d3aa6b303d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Preparing Local Taxonomy Environment ---\n",
            "Local taxonomy environment not found. Starting full extraction process...\n",
            "\n",
            "--- Unzipping all taxonomy packages ---\n",
            "Processing: es-bde.zip...\n",
            "  -> Detected as 7-Zip archive. Extracting with 7z...\n",
            "Processing: es-bde-aux.zip...\n",
            "  -> Detected as 7-Zip archive. Extracting with 7z...\n",
            "Processing: eu-eurofiling.zip...\n",
            "  -> Detected as standard Zip archive. Extracting...\n",
            "Processing: srf-eac_full_taxonomy_0.zip...\n",
            "  -> Detected as standard Zip archive. Extracting...\n",
            "Processing: Full_taxonomy_release_4.1.zip...\n",
            "  -> Detected as standard Zip archive. Extracting...\n",
            "\n",
            "✅ Local taxonomy environment is now ready. All 5 packages unzipped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate XBRL report"
      ],
      "metadata": {
        "id": "hAVZOmEtUWyT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm2lXBdfRuaQ",
        "outputId": "58a2091f-634f-48a2-b23f-a56f6a121a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Main Script ---\n",
            "\n",
            " Checking Arelle version...\n",
            "  -> Arelle(r) 2.37.28.dev9+gcf964068 (64bit)\n",
            "\n",
            "[2] Checking taxonomy package versions (last modified date)...\n",
            "- es-bde.zip: Last Modified 2025-06-19 10:58:56\n",
            "- es-bde-aux.zip: Last Modified 2025-06-19 09:42:35\n",
            "- eu-eurofiling.zip: Last Modified 2025-06-19 09:39:57\n",
            "- srf-eac_full_taxonomy_0.zip: Last Modified 2025-06-19 09:44:15\n",
            "- Full_taxonomy_release_4.1.zip: Last Modified 2025-06-19 09:51:48\n",
            "\n",
            "[1] Reading data and mapping from 'EP_4_MAY25.xlsx'...\n",
            "Data extraction complete.\n",
            "\n",
            "[2] Generating candidate XBRL file using lxml...\n",
            "Candidate file 'ES6885_ES_EP_EDE_EPM1_20250531_20250625.xbrl' saved to Colab session.\n",
            "\n",
            "[3] Starting taxonomy validation with Arelle command line...\n",
            "Running Arelle...\n",
            "\n",
            "--- Arelle Validation Report ---\n",
            "\n",
            "FILE NOT FOUND ERROR: [Errno 2] No such file or directory: 'arelle_validation_log.txt'. Please ensure all source files are available.\n"
          ]
        }
      ],
      "source": [
        "# --- Main Script to Generate, Validate, and Package XBRL Report ---\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    This script automates the monthly generation and validation of a regulatory XBRL report.\n",
        "    It uses the lxml library for robust XML handling and invokes the Arelle command-line\n",
        "    tool for official validation.\n",
        "\n",
        "    Workflow:\n",
        "    1.  Configuration: Sets up all necessary file paths and parameters.\n",
        "    2.  Data Extraction: Reads a mapping file and data from an Excel workbook.\n",
        "    3.  XBRL Generation (with lxml): Loads a source XBRL template, updates dates and\n",
        "        financial values, and saves the new file, correctly preserving all namespaces.\n",
        "    4.  Arelle Validation: Invokes the Arelle command-line to perform a full, offline\n",
        "        taxonomy validation on the newly generated file.\n",
        "    5.  Reporting & Packaging: Reports on the validation results and creates a final\n",
        "        .zip archive if the report is valid.\n",
        "\n",
        "    Prerequisites:\n",
        "    - This script must be run after the setup cells (Installation, Drive Mount,\n",
        "      Imports, and Unzipping) have all completed successfully.\n",
        "    - lxml must be installed, and `from lxml import etree as ET` must be in the Imports cell.\n",
        "    - Source Excel and XBRL files must be available in the specified locations.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting Main Script ---\")\n",
        "\n",
        "    # --- Initialize an empty list to store log messages ---\n",
        "    change_log = [f\"Modification process started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"]\n",
        "\n",
        "    # --- Check Arelle Version ---\n",
        "    print(\"\\n Checking Arelle version...\")\n",
        "    version_command = [\"arelleCmdLine\", \"--version\"]\n",
        "    result = subprocess.run(version_command, capture_output=True, text=True, check=True)\n",
        "    # The version info is usually in the first line of the standard output\n",
        "    version_info = result.stdout.strip().split('\\n')[0]\n",
        "    print(f\"  -> {version_info}\")\n",
        "    # Add the version to our log file for record-keeping\n",
        "    change_log.append(version_info)\n",
        "\n",
        "    # --- [2] Define File Paths and Check Taxonomy Versions ---\n",
        "    drive_path = \"/content/drive/MyDrive/BDE_REPORTING_SCRIPT/XBRL_Taxonomies/\"\n",
        "    taxonomy_zip_files = [\n",
        "        drive_path + 'es-bde.zip',\n",
        "        drive_path + 'es-bde-aux.zip',\n",
        "        drive_path + 'eu-eurofiling.zip',\n",
        "        drive_path + 'srf-eac_full_taxonomy_0.zip',\n",
        "        drive_path + 'Full_taxonomy_release_4.1.zip'\n",
        "    ]\n",
        "\n",
        "    # --- NEW: Check the last modified date of each taxonomy package ---\n",
        "    print(\"\\n[2] Checking taxonomy package versions (last modified date)...\")\n",
        "    change_log.append(\"\\n[TAXONOMY VERSIONS USED]\")\n",
        "    for zip_file_path in taxonomy_zip_files:\n",
        "        if os.path.exists(zip_file_path):\n",
        "            mod_time = os.path.getmtime(zip_file_path)\n",
        "            mod_date_str = datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M:%S')\n",
        "            log_message = f\"- {os.path.basename(zip_file_path)}: Last Modified {mod_date_str}\"\n",
        "            print(log_message)\n",
        "            change_log.append(log_message)\n",
        "        else:\n",
        "            print(f\"- WARNING: Could not find taxonomy package: {os.path.basename(zip_file_path)}\")\n",
        "\n",
        "    # --- Define All File Paths and Parameters ---\n",
        "    drive_path = \"/content/drive/MyDrive/BDE_REPORTING_SCRIPT/XBRL_Taxonomies/\"\n",
        "    local_taxonomy_folder = 'local_taxonomies'\n",
        "    excel_file = 'EP_4_MAY25.xlsx'\n",
        "    source_xbrl_file = 'ES6885_ES_EP_EDE_EPM1_20250430_20250506.xbrl'\n",
        "    data_sheet_name = 'EP_4-2'\n",
        "    mapping_sheet_name = 'mapping_ep4_2'\n",
        "\n",
        "    try:\n",
        "        # --- [1] Read Mapping and Data from Excel ---\n",
        "        print(f\"\\n[1] Reading data and mapping from '{excel_file}'...\")\n",
        "        mapping_df = pd.read_excel(excel_file, sheet_name=mapping_sheet_name)\n",
        "\n",
        "        mapping_dict = dict(zip(mapping_df['Excel_Code'].astype(str), mapping_df['XBRL_Context_Ref']))\n",
        "        codes_to_find = set(mapping_dict.keys())\n",
        "\n",
        "        workbook = openpyxl.load_workbook(excel_file, data_only=True)\n",
        "        data_sheet = workbook[data_sheet_name]\n",
        "\n",
        "        label_row_index = -1; max_hits = 0\n",
        "        for i, row in enumerate(data_sheet.iter_rows()):\n",
        "            hits_in_row = sum(1 for cell in row if re.search(r'\\(([a-z])\\)', str(cell.value)) and re.search(r'\\(([a-z])\\)', str(cell.value)).group(1) in codes_to_find)\n",
        "            if hits_in_row > max_hits: max_hits = hits_in_row; label_row_index = i + 1\n",
        "        if label_row_index == -1: raise ValueError(\"Could not identify the main label row in the Excel sheet.\")\n",
        "\n",
        "        new_data_values = {}\n",
        "        label_row = list(data_sheet.iter_rows(min_row=label_row_index, max_row=label_row_index))[0]\n",
        "        for cell in label_row:\n",
        "            match = re.search(r'\\(([a-z])\\)', str(cell.value))\n",
        "            if match and match.group(1) in mapping_dict:\n",
        "                letter_code = match.group(1)\n",
        "                data_cell = data_sheet.cell(row=cell.row + 1, column=cell.column + 2)\n",
        "                new_data_values[letter_code] = data_cell.value\n",
        "        print(\"Data extraction complete.\")\n",
        "\n",
        "        # --- [2] Generate the Candidate XBRL File using lxml ---\n",
        "        print(f\"\\n[2] Generating candidate XBRL file using lxml...\")\n",
        "\n",
        "        # Use lxml's parser. This correctly handles all namespace information.\n",
        "        parser = ET.XMLParser(remove_blank_text=True)\n",
        "        tree = ET.parse(source_xbrl_file, parser)\n",
        "        root = tree.getroot()\n",
        "        # Get the namespace map from the parsed document\n",
        "        ns_map = root.nsmap\n",
        "\n",
        "        # Update dates and log the change\n",
        "        original_date_str = root.find('.//xbrli:instant', namespaces=ns_map).text\n",
        "        last_day_of_next_month = (date.fromisoformat(original_date_str).replace(day=1) + relativedelta(months=1))\n",
        "        last_day_of_next_month = last_day_of_next_month.replace(day=calendar.monthrange(last_day_of_next_month.year, last_day_of_next_month.month)[1])\n",
        "        new_date_str = last_day_of_next_month.isoformat()\n",
        "\n",
        "        # --- Log the date change before making it ---\n",
        "        if original_date_str != new_date_str:\n",
        "             change_log.append(f\"\\n[DATE UPDATE]\\n- Changed report date from '{original_date_str}' to '{new_date_str}'\")\n",
        "\n",
        "        for date_element in root.findall('.//xbrli:instant', namespaces=ns_map):\n",
        "            date_element.text = new_date_str\n",
        "\n",
        "        # Update facts and log each change\n",
        "        for letter_code, context_ref in mapping_dict.items():\n",
        "            if letter_code in new_data_values and new_data_values[letter_code] is not None:\n",
        "                new_value = new_data_values[letter_code]\n",
        "                fact_to_update = root.find(f\".//*[@contextRef='{context_ref}']\", namespaces=ns_map)\n",
        "                if fact_to_update is not None:\n",
        "                    old_value = fact_to_update.text\n",
        "                    # --- Log the change if the value is different ---\n",
        "                    if str(old_value) != str(new_value):\n",
        "                        log_message = f\"- Context '{context_ref}' (Code: {letter_code}): Changed value from '{old_value}' to '{new_value}'\"\n",
        "                        change_log.append(log_message)\n",
        "                    # Make the change\n",
        "                    fact_to_update.text = str(new_value)\n",
        "\n",
        "        # Generate new filename\n",
        "        reported_date_formatted = last_day_of_next_month.strftime('%Y%m%d')\n",
        "        today_formatted = datetime.now().strftime('%Y%m%d')\n",
        "        new_filename = f\"ES6885_ES_EP_EDE_EPM1_{reported_date_formatted}_{today_formatted}.xbrl\"\n",
        "\n",
        "        # Write the file using lxml. This preserves all namespaces correctly.\n",
        "        tree.write(new_filename, pretty_print=True, xml_declaration=True, encoding='UTF-8')\n",
        "        print(f\"Candidate file '{new_filename}' saved to Colab session.\")\n",
        "\n",
        "        # --- [3] Validate via Arelle Command Line Interface ---\n",
        "        print(f\"\\n[3] Starting taxonomy validation with Arelle command line...\")\n",
        "        command = [\n",
        "            \"arelleCmdLine\", \"--file\", new_filename, \"--validate\",\n",
        "            \"--remap-url\", f\"http://www.bde.es/|{os.path.join(local_taxonomy_folder, 'www.bde.es/')}\",\n",
        "            \"--remap-url\", f\"http://www.eba.europa.eu/|{os.path.join(local_taxonomy_folder, 'www.eba.europa.eu/')}\",\n",
        "            \"--remap-url\", f\"http://www.eurofiling.info/|{os.path.join(local_taxonomy_folder, 'www.eurofiling.info/')}\",\n",
        "            \"--logFile\", \"arelle_validation_log.txt\", \"--logFormat\", \"text\"\n",
        "        ]\n",
        "        print(\"Running Arelle...\")\n",
        "        subprocess.run(command)\n",
        "\n",
        "        # --- [4] Read and display the Arelle report ---\n",
        "        print(\"\\n--- Arelle Validation Report ---\")\n",
        "        validation_successful = False\n",
        "        with open(\"arelle_validation_log.txt\", \"r\") as log_file:\n",
        "            log_contents = log_file.read()\n",
        "\n",
        "        if '[error]' not in log_contents.lower():\n",
        "            print(\"✅ TAXONOMY VALIDATION SUCCESS: No critical errors reported.\")\n",
        "            validation_successful = True\n",
        "        else:\n",
        "            print(\"❌ TAXONOMY VALIDATION FAILED: Errors were reported by Arelle.\")\n",
        "            print(\"\\nFull Log:\")\n",
        "            print(log_contents.strip())\n",
        "\n",
        "        # --- [5] Create the Final .ZIP Archive if validation passed ---\n",
        "        if validation_successful:\n",
        "            print(f\"\\n[5] Creating final .zip archive...\")\n",
        "            base_name = os.path.splitext(new_filename)[0]\n",
        "            output_zip_filename = base_name + \".zip\"\n",
        "            with zipfile.ZipFile(output_zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "                zipf.write(new_filename, arcname=os.path.basename(new_filename))\n",
        "            print(f\"✅ Success! Created '{output_zip_filename}'\")\n",
        "\n",
        "        # --- STEP 5: WRITE THE MODIFICATION LOG FILE ---\n",
        "        log_filename = \"modification_log.txt\"\n",
        "        print(f\"\\n[5] Writing modification log to '{log_filename}'...\")\n",
        "        with open(log_filename, \"w\") as f:\n",
        "            for line in change_log:\n",
        "                f.write(line + \"\\n\")\n",
        "        print(\"✅ Log file created successfully.\")\n",
        "\n",
        "        print(\"\\n--- PROCESS COMPLETE ---\")\n",
        "\n",
        "    except FileNotFoundError as fnf_error:\n",
        "        print(f\"\\nFILE NOT FOUND ERROR: {fnf_error}. Please ensure all source files are available.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "\n",
        "# --- Execute the main function ---\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except NameError as ne:\n",
        "        print(f\"\\nSCRIPT SETUP ERROR: A required library was not imported. Please run the 'Import Libraries' cell first. Details: {ne}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nA critical error occurred: {e}\")"
      ]
    }
  ]
}